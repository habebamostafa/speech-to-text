# -*- coding: utf-8 -*-
import streamlit as st
import tensorflow as tf
from tensorflow import keras
import numpy as np
import json
import pickle
import sounddevice as sd
from scipy.io import wavfile
import wave
import os
import tempfile
import time
from jiwer import wer, cer

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
st.set_page_config(
    page_title="Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…",
    page_icon="ğŸ¤",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ØªØ®ØµÙŠØµ Ø§Ù„ØªØµÙ…ÙŠÙ…
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .result-box {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        border-right: 5px solid #1f77b4;
        margin: 10px 0;
    }
    .metric-box {
        background-color: #ffffff;
        padding: 15px;
        border-radius: 8px;
        border-left: 4px solid #ff6b6b;
        margin: 5px 0;
    }
</style>
""", unsafe_allow_html=True)

# Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
st.markdown('<h1 class="main-header">ğŸ¤ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… - STT</h1>', unsafe_allow_html=True)

# Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
with st.sidebar:
    st.header("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    st.subheader("ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬")
    model_loaded = False
    
    if st.button("ğŸ”„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", use_container_width=True):
        with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬..."):
            try:
                # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
                model = keras.models.load_model('my_model (1).h5', compile=False)
                
                with open('improved_model_config.json', 'r', encoding='utf-8') as f:
                    config = json.load(f)
                
                with open('improved_preprocessors.pkl', 'rb') as f:
                    preprocessors = pickle.load(f)
                    char_to_num = preprocessors['char_to_num']
                    num_to_char = preprocessors['num_to_char']
                
                st.session_state.model = model
                st.session_state.config = config
                st.session_state.char_to_num = char_to_num
                st.session_state.num_to_char = num_to_char
                st.session_state.model_loaded = True
                
                st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­!")
                
            except Exception as e:
                st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
    
    st.divider()
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ³Ø¬ÙŠÙ„
    st.subheader("Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ³Ø¬ÙŠÙ„")
    duration = st.slider("â±ï¸ Ù…Ø¯Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„ (Ø«ÙˆØ§Ù†ÙŠ)", 1, 10, 5)
    sample_rate = st.selectbox("ğŸ“Š Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª", [16000, 22050, 44100], index=0)

# Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
if not st.session_state.get('model_loaded', False):
    st.warning("âš ï¸ ÙŠØ±Ø¬Ù‰ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙˆÙ„Ø§Ù‹ Ù…Ù† Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ")
    st.stop()

# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ù…Ù† session state
model = st.session_state.model
config = st.session_state.config
char_to_num = st.session_state.char_to_num
num_to_char = st.session_state.num_to_char

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
frame_length = config['frame_length']
frame_step = config['frame_step']
fft_length = config['fft_length']

# Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
def process_audio_file(audio_path):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù ØµÙˆØªÙŠ ÙˆØªØ­ÙˆÙŠÙ„Ù‡ Ù„Ø³Ø¨ÙŠÙƒØªØ±ÙˆØ¬Ø±Ø§Ù…"""
    try:
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
        audio = tf.io.read_file(audio_path)
        audio, sample_rate = tf.audio.decode_wav(audio)
        audio = tf.squeeze(audio, axis=-1)
        audio = tf.cast(audio, tf.float32)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ø¨ÙŠÙƒØªØ±ÙˆØ¬Ø±Ø§Ù…
        spectrogram = tf.signal.stft(
            audio,
            frame_length=frame_length,
            frame_step=frame_step,
            fft_length=fft_length
        )
        spectrogram = tf.abs(spectrogram)
        spectrogram = tf.math.pow(spectrogram, 0.5)
        
        # ØªØ·Ø¨ÙŠØ¹
        means = tf.math.reduce_mean(spectrogram, 1, keepdims=True)
        stddevs = tf.math.reduce_std(spectrogram, 1, keepdims=True)
        spectrogram = (spectrogram - means) / (stddevs + 1e-10)
        
        return spectrogram, sample_rate.numpy()
    
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù: {e}")
        return None, None

def decode_prediction(pred):
    """ÙÙƒ ØªØ´ÙÙŠØ± ØªÙ†Ø¨Ø¤ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
    input_len = np.ones(pred.shape[0]) * pred.shape[1]
    
    # Greedy decoding
    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]
    
    # ØªØ­ÙˆÙŠÙ„ Ù„Ù†Øµ
    output_text = []
    for result in results:
        chars = num_to_char(result)
        text = tf.strings.reduce_join(chars).numpy().decode("utf-8")
        text = ' '.join(text.split()).strip()
        output_text.append(text)
    
    return output_text[0] if output_text else ""

def predict_from_audio(audio_path):
    """Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ù†Øµ Ù…Ù† Ù…Ù„Ù ØµÙˆØªÙŠ"""
    try:
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª
        spectrogram, sample_rate = process_audio_file(audio_path)
        if spectrogram is None:
            return None
        
        # Ø¥Ø¶Ø§ÙØ© Ø¨ÙØ¹Ø¯ Ø§Ù„Ø¯ÙØ¹Ø©
        spectrogram = tf.expand_dims(spectrogram, axis=0)
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤
        prediction = model(spectrogram, training=False)
        text = decode_prediction(prediction)
        
        return text
    
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤: {e}")
        return None

# Ø¯Ø§Ù„Ø© ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª
def record_audio(duration=5, sample_rate=16000):
    """ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª Ù…Ù† Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†"""
    try:
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ù…Ø¤Ù‚Øª
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
        temp_filename = temp_file.name
        temp_file.close()
        
        # Ø§Ù„ØªØ³Ø¬ÙŠÙ„
        recording = sd.rec(
            int(duration * sample_rate),
            samplerate=sample_rate,
            channels=1,
            dtype='int16'
        )
        
        # Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù…
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i in range(duration):
            time.sleep(1)
            progress = (i + 1) / duration
            progress_bar.progress(progress)
            status_text.text(f"ğŸ™ï¸ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„... {i + 1}/{duration} Ø«Ø§Ù†ÙŠØ©")
        
        sd.wait()  # Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
        
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
        wavfile.write(temp_filename, sample_rate, recording)
        
        progress_bar.empty()
        status_text.empty()
        
        return temp_filename
    
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„: {e}")
        return None

# ØªØ¨ÙˆÙŠØ¨Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
tab1, tab2, tab3 = st.tabs(["ğŸ¤ ØªØ³Ø¬ÙŠÙ„ ØµÙˆØªÙŠ", "ğŸ“ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù", "ğŸ“Š ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"])

with tab1:
    st.header("ØªØ³Ø¬ÙŠÙ„ ØµÙˆØªÙŠ Ù…Ø¨Ø§Ø´Ø±")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.subheader("Ø§Ù„ØªØ³Ø¬ÙŠÙ„")
        if st.button("ğŸ™ï¸ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„", use_container_width=True):
            audio_file = record_audio(duration=duration, sample_rate=sample_rate)
            if audio_file:
                st.session_state.recorded_audio = audio_file
                st.success("âœ… ØªÙ… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­!")
                
                # ØªØ´ØºÙŠÙ„ Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø³Ø¬Ù„
                st.audio(audio_file, format='audio/wav')
    
    with col2:
        st.subheader("Ø§Ù„Ù†ØªÙŠØ¬Ø©")
        if st.session_state.get('recorded_audio'):
            if st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ³Ø¬ÙŠÙ„", use_container_width=True):
                with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…..."):
                    prediction = predict_from_audio(st.session_state.recorded_audio)
                    
                    if prediction:
                        st.markdown('<div class="result-box">', unsafe_allow_html=True)
                        st.subheader("ğŸ“ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:")
                        st.success(prediction)
                        st.markdown('</div>', unsafe_allow_html=True)
                        
                        # Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø©
                        st.session_state.last_prediction = prediction

with tab2:
    st.header("ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù ØµÙˆØªÙŠ")
    
    uploaded_file = st.file_uploader("Ø§Ø®ØªØ± Ù…Ù„Ù ØµÙˆØªÙŠ (WAV)", type=['wav'])
    
    if uploaded_file is not None:
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            audio_path = tmp_file.name
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù„Ù
        st.audio(uploaded_file, format='audio/wav')
        
        if st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„Ù", use_container_width=True):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…..."):
                prediction = predict_from_audio(audio_path)
                
                if prediction:
                    st.markdown('<div class="result-box">', unsafe_allow_html=True)
                    st.subheader("ğŸ“ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:")
                    st.success(prediction)
                    st.markdown('</div>', unsafe_allow_html=True)
                    
                    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
                    os.unlink(audio_path)

with tab3:
    st.header("ØªÙ‚ÙŠÙŠÙ… Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬")
    
    st.subheader("Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø¹ Ù†Øµ Ù…Ø±Ø¬Ø¹ÙŠ")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        reference_text = st.text_area("âœï¸ Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ:", 
                                    placeholder="Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ø§Ù„ØµØ­ÙŠØ­ Ù‡Ù†Ø§...")
    
    with col2:
        predicted_text = st.text_area("ğŸ¤– Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:", 
                                    value=st.session_state.get('last_prediction', ''),
                                    placeholder="Ø³ÙŠØ¸Ù‡Ø± Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ù‡Ù†Ø§...")
    
    if st.button("ğŸ“Š Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…", use_container_width=True) and reference_text and predicted_text:
        try:
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
            wer_score = wer(reference_text, predicted_text)
            cer_score = cer(reference_text, predicted_text)
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown('<div class="metric-box">', unsafe_allow_html=True)
                st.metric("Word Error Rate (WER)", f"{wer_score:.4f}")
                st.markdown('</div>', unsafe_allow_html=True)
                
            with col2:
                st.markdown('<div class="metric-box">', unsafe_allow_html=True)
                st.metric("Character Error Rate (CER)", f"{cer_score:.4f}")
                st.markdown('</div>', unsafe_allow_html=True)
            
            # ØªÙØ³ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            st.subheader("ğŸ“ˆ ØªÙØ³ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
            if wer_score < 0.1:
                st.success("ğŸ”¹ **Ù…Ù…ØªØ§Ø²**: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¹Ù…Ù„ Ø¨Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹")
            elif wer_score < 0.3:
                st.info("ğŸ”¸ **Ø¬ÙŠØ¯**: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¹Ù…Ù„ Ø¨Ø¯Ù‚Ø© Ù…Ù‚Ø¨ÙˆÙ„Ø©")
            else:
                st.warning("ğŸ”º **ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ†**: Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù†Ø®ÙØ¶Ø©")
                
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³: {e}")

# Ù‚Ø³Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
with st.expander("â„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"):
    st.markdown("""
    ### ğŸ“‹ Ù…ÙˆØ§ØµÙØ§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:
    - **Ø§Ù„Ù†Ù…ÙˆØ°Ø¬**: DeepSpeech 2 Architecture
    - **Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„**: Ù…Ù„ÙØ§Øª ØµÙˆØªÙŠØ© WAV
    - **Ø§Ù„Ù…Ø®Ø±Ø¬**: Ù†ØµÙˆØµ Ù…ÙƒØªÙˆØ¨Ø©
    - **Ø§Ù„Ø¯Ù‚Ø©**: ØªØ®ØªÙ„Ù Ø­Ø³Ø¨ Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØª
    
    ### ğŸ’¡ Ù†ØµØ§Ø¦Ø­ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:
    - Ø§Ø³ØªØ®Ø¯Ù… Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† Ø¬ÙŠØ¯
    - ØªÙƒÙ„Ù… Ø¨ÙˆØ¶ÙˆØ­ ÙˆØ¨Ø·Ø¡ Ù…Ø¹ØªØ¯Ù„
    - ØªØ¬Ù†Ø¨ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ Ø§Ù„Ø®Ù„ÙÙŠØ©
    - Ø§Ø®ØªØ¨Ø± ÙÙŠ Ø¨ÙŠØ¦Ø© Ù‡Ø§Ø¯Ø¦Ø©
    """)

# Ø§Ù„ØªØ´ØºÙŠÙ„
if __name__ == "__main__":
    # ØªÙ‡ÙŠØ¦Ø© session state
    if 'model_loaded' not in st.session_state:
        st.session_state.model_loaded = False
    if 'recorded_audio' not in st.session_state:
        st.session_state.recorded_audio = None
    if 'last_prediction' not in st.session_state:
        st.session_state.last_prediction = ""