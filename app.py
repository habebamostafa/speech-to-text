# -*- coding: utf-8 -*-
import streamlit as st
import tensorflow as tf
from tensorflow import keras
import numpy as np
import tempfile
import os
import time

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„ØµÙˆØª
try:
    import pyaudio
    import wave
    PYAUDIO_AVAILABLE = True
except ImportError:
    PYAUDIO_AVAILABLE = False

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
st.set_page_config(
    page_title="Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…",
    page_icon="ğŸ¤",
    layout="wide"
)

# Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .result-box {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        border-right: 5px solid #1f77b4;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)

st.markdown('<h1 class="main-header">ğŸ¤ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…</h1>', unsafe_allow_html=True)
import os
st.write("Current directory:", os.getcwd())
st.write("Files in directory:", os.listdir())

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
@st.cache_resource
def load_model():
    """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† my_model (1).h5"""
    try:
        model = keras.models.load_model('my_model.h5', compile=False)
        return model
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
        return None

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
if 'model' not in st.session_state:
    with st.spinner("ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬..."):
        model = load_model()
        if model is not None:
            st.session_state.model = model
            st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­!")
        else:
            st.stop()

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø«Ø§Ø¨ØªØ© (Ù†ÙØ³ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨)
frame_length = 256
frame_step = 160
fft_length = 384

# Ù…ÙØ±Ø¯Ø§Øª Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© (Ù†ÙØ³ Ø§Ù„ØªØ¯Ø±ÙŠØ¨)
characters = [x for x in "abcdefghijklmnopqrstuvwxyz'?! "]
char_to_num = tf.keras.layers.StringLookup(vocabulary=characters, oov_token="")
num_to_char = tf.keras.layers.StringLookup(
    vocabulary=char_to_num.get_vocabulary(), oov_token="", invert=True
)

# Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
def process_audio_file(audio_path):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù ØµÙˆØªÙŠ - Ù†ÙØ³ Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
    try:
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
        audio = tf.io.read_file(audio_path)
        audio, sample_rate = tf.audio.decode_wav(audio)
        audio = tf.squeeze(audio, axis=-1)
        audio = tf.cast(audio, tf.float32)

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ø¨ÙŠÙƒØªØ±ÙˆØ¬Ø±Ø§Ù…
        spectrogram = tf.signal.stft(
            audio,
            frame_length=frame_length,
            frame_step=frame_step,
            fft_length=fft_length
        )
        spectrogram = tf.abs(spectrogram)
        spectrogram = tf.math.pow(spectrogram, 0.5)

        # ØªØ·Ø¨ÙŠØ¹
        means = tf.math.reduce_mean(spectrogram, 1, keepdims=True)
        stddevs = tf.math.reduce_std(spectrogram, 1, keepdims=True)
        spectrogram = (spectrogram - means) / (stddevs + 1e-10)

        return spectrogram
    
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù: {e}")
        return None

def decode_prediction(pred):
    """ÙÙƒ ØªØ´ÙÙŠØ± Ø§Ù„ØªÙ†Ø¨Ø¤ - Ù†ÙØ³ Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
    try:
        input_len = np.ones(pred.shape[0]) * pred.shape[1]
        results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]
        
        output_text = []
        for result in results:
            chars = num_to_char(result)
            text = tf.strings.reduce_join(chars).numpy().decode("utf-8")
            output_text.append(text)
        
        return output_text[0] if output_text else ""
    
    except Exception as e:
        return ""

def predict_from_audio(audio_path):
    """Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ù†Øµ Ù…Ù† Ù…Ù„Ù ØµÙˆØªÙŠ"""
    try:
        spectrogram = process_audio_file(audio_path)
        if spectrogram is None:
            return None
        
        spectrogram = tf.expand_dims(spectrogram, axis=0)
        prediction = st.session_state.model(spectrogram, training=False)
        text = decode_prediction(prediction)
        
        return text
    
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤: {e}")
        return None

# Ø¯Ø§Ù„Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„
def record_audio(duration=5, sample_rate=16000):
    """ØªØ³Ø¬ÙŠÙ„ ØµÙˆØª Ù…Ù† Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†"""
    try:
        chunk = 1024
        format = pyaudio.paInt16
        
        p = pyaudio.PyAudio()
        stream = p.open(
            format=format,
            channels=1,
            rate=sample_rate,
            input=True,
            frames_per_buffer=chunk
        )
        
        st.info("ğŸ™ï¸ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„... ØªÙƒÙ„Ù… Ø§Ù„Ø¢Ù†!")
        frames = []
        
        total_chunks = int((sample_rate / chunk) * duration)
        progress_bar = st.progress(0)
        
        for i in range(total_chunks):
            data = stream.read(chunk)
            frames.append(data)
            progress_bar.progress((i + 1) / total_chunks)
        
        stream.stop_stream()
        stream.close()
        p.terminate()
        progress_bar.empty()
        
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
        temp_filename = temp_file.name
        temp_file.close()
        
        wf = wave.open(temp_filename, 'wb')
        wf.setnchannels(1)
        wf.setsampwidth(p.get_sample_size(format))
        wf.setframerate(sample_rate)
        wf.writeframes(b''.join(frames))
        wf.close()
        
        st.success("âœ… ØªÙ… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­!")
        return temp_filename
        
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„: {e}")
        return None

# ØªØ¨ÙˆÙŠØ¨Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
tab1, tab2 = st.tabs(["ğŸ¤ ØªØ³Ø¬ÙŠÙ„ Ù…Ù† Ø§Ù„Ù…Ø§ÙŠÙƒ", "ğŸ“ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù ØµÙˆØªÙŠ"])

with tab1:
    st.header("Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù…Ù† Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†")
    
    if not PYAUDIO_AVAILABLE:
        st.error("""
        âŒ **PyAudio ØºÙŠØ± Ù…Ø«Ø¨Øª**
        
        Ù„Ù„ØªØ³Ø¬ÙŠÙ„ Ù…Ù† Ø§Ù„Ù…Ø§ÙŠÙƒØ±ÙˆÙÙˆÙ†:
        ```bash
        pip install pyaudio
        ```
        """)
    else:
        col1, col2 = st.columns([1, 1])
        
        with col1:
            duration = st.slider("Ù…Ø¯Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„ (Ø«ÙˆØ§Ù†ÙŠ)", 1, 10, 3)
            
            if st.button("âºï¸ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„", use_container_width=True):
                audio_file = record_audio(duration=duration)
                if audio_file:
                    st.session_state.recorded_audio = audio_file
                    st.rerun()
            
            if st.session_state.get('recorded_audio'):
                st.audio(st.session_state.recorded_audio, format='audio/wav')
                
                if st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ³Ø¬ÙŠÙ„", use_container_width=True):
                    with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…..."):
                        prediction = predict_from_audio(st.session_state.recorded_audio)
                        if prediction:
                            st.session_state.last_prediction = prediction
                            st.rerun()
        
        with col2:
            if st.session_state.get('last_prediction'):
                st.markdown('<div class="result-box">', unsafe_allow_html=True)
                st.success("**Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:**")
                st.code(st.session_state.last_prediction)
                st.markdown('</div>', unsafe_allow_html=True)

with tab2:
    st.header("ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù ØµÙˆØªÙŠ")
    
    uploaded_audio = st.file_uploader("Ø§Ø®ØªØ± Ù…Ù„Ù ØµÙˆØªÙŠ WAV", type=['wav'])
    
    if uploaded_audio is not None:
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
            tmp_file.write(uploaded_audio.getvalue())
            audio_path = tmp_file.name
        
        st.audio(uploaded_audio, format='audio/wav')
        
        if st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„Ù", use_container_width=True):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…..."):
                prediction = predict_from_audio(audio_path)
                
                if prediction:
                    st.markdown('<div class="result-box">', unsafe_allow_html=True)
                    st.success("**Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:**")
                    st.code(prediction)
                    st.markdown('</div>', unsafe_allow_html=True)
                
                try:
                    os.unlink(audio_path)
                except:
                    pass

# Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
with st.expander("â„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"):
    st.markdown("""
    **Ù…ÙˆØ§ØµÙØ§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:**
    - Ù…Ø¯Ø±Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
    - Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª: LJSpeech
    - Ù…ÙØ±Ø¯Ø§Øª: 31 Ø­Ø±Ù Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ
    - Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©:
      - Frame Length: 256
      - Frame Step: 160  
      - FFT Length: 384
    """)

# ØªØ°ÙŠÙŠÙ„ Ø§Ù„ØµÙØ­Ø©
st.markdown("---")
st.markdown("ğŸ¤ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… - ÙŠØ¹Ù…Ù„ Ø¨Ù€ my_model (1).h5")