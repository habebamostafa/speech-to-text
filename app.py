# -*- coding: utf-8 -*-
import streamlit as st
import tensorflow as tf
from tensorflow import keras
import numpy as np
import json
import pickle
import tempfile
import os
import time
from jiwer import wer, cer
import io
import base64

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„ØµÙˆØª
try:
    import sounddevice as sd
    from scipy.io import wavfile
    AUDIO_AVAILABLE = True
except ImportError as e:
    st.error(f"âŒ Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„ØµÙˆØª ØºÙŠØ± Ù…Ø«Ø¨ØªØ©: {e}")
    AUDIO_AVAILABLE = False

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
st.set_page_config(
    page_title="Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… - Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ",
    page_icon="ğŸ¤",
    layout="wide"
)

# ØªØ®ØµÙŠØµ Ø§Ù„ØªØµÙ…ÙŠÙ…
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .result-box {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        border-right: 5px solid #1f77b4;
        margin: 10px 0;
    }
    .recording-box {
        background-color: #fff3cd;
        padding: 20px;
        border-radius: 10px;
        border-left: 4px solid #ffc107;
        margin: 10px 0;
    }
    .success-box {
        background-color: #d1ecf1;
        padding: 20px;
        border-radius: 10px;
        border-left: 4px solid #0c5460;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)

# Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
st.markdown('<h1 class="main-header">ğŸ¤ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… - Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ</h1>', unsafe_allow_html=True)

# ØªÙ‡ÙŠØ¦Ø© Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø©
if 'model' not in st.session_state:
    st.session_state.model = None
if 'config' not in st.session_state:
    st.session_state.config = None
if 'char_to_num' not in st.session_state:
    st.session_state.char_to_num = None
if 'num_to_char' not in st.session_state:
    st.session_state.num_to_char = None
if 'last_prediction' not in st.session_state:
    st.session_state.last_prediction = ""
if 'is_recording' not in st.session_state:
    st.session_state.is_recording = False

# Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
with st.sidebar:
    st.header("âš™ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬")
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    uploaded_model = st.file_uploader("Ø±ÙØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (.h5 Ø£Ùˆ .keras)", type=['h5', 'keras'])
    uploaded_config = st.file_uploader("Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª (.json)", type=['json'])
    uploaded_preprocessors = st.file_uploader("Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø§Øª (.pkl)", type=['pkl'])
    
    if st.button("ğŸ”„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", use_container_width=True):
        if uploaded_model and uploaded_config and uploaded_preprocessors:
            with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬..."):
                try:
                    # Ø­ÙØ¸ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©
                    model_path = tempfile.NamedTemporaryFile(delete=False, suffix='.h5').name
                    with open(model_path, 'wb') as f:
                        f.write(uploaded_model.getvalue())
                    
                    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
                    model = keras.models.load_model(model_path, compile=False)
                    st.session_state.model = model
                    
                    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
                    config = json.load(uploaded_config)
                    st.session_state.config = config
                    
                    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø§Øª
                    preprocessors = pickle.load(uploaded_preprocessors)
                    st.session_state.char_to_num = preprocessors.get('char_to_num')
                    st.session_state.num_to_char = preprocessors.get('num_to_char')
                    
                    st.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­!")
                    
                    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
                    os.unlink(model_path)
                    
                except Exception as e:
                    st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
        else:
            st.error("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©")
    
    st.divider()
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ³Ø¬ÙŠÙ„
    if AUDIO_AVAILABLE:
        st.header("ğŸ™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ³Ø¬ÙŠÙ„")
        st.session_state.duration = st.slider("Ù…Ø¯Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„ (Ø«ÙˆØ§Ù†ÙŠ)", 1, 15, 5)
        st.session_state.sample_rate = st.selectbox("Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª", [16000, 22050, 44100], index=0)
    else:
        st.error("âŒ Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„ØµÙˆØª ØºÙŠØ± Ù…Ø«Ø¨ØªØ©")

# Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØªÙŠØ©
def process_audio_file(audio_path):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù ØµÙˆØªÙŠ ÙˆØªØ­ÙˆÙŠÙ„Ù‡ Ù„Ø³Ø¨ÙŠÙƒØªØ±ÙˆØ¬Ø±Ø§Ù…"""
    try:
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
        audio = tf.io.read_file(audio_path)
        audio, sample_rate = tf.audio.decode_wav(audio)
        audio = tf.squeeze(audio, axis=-1)
        audio = tf.cast(audio, tf.float32)
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ù† config
        config = st.session_state.config
        frame_length = config.get('frame_length', 256)
        frame_step = config.get('frame_step', 160) 
        fft_length = config.get('fft_length', 384)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ø¨ÙŠÙƒØªØ±ÙˆØ¬Ø±Ø§Ù…
        spectrogram = tf.signal.stft(
            audio,
            frame_length=frame_length,
            frame_step=frame_step,
            fft_length=fft_length
        )
        spectrogram = tf.abs(spectrogram)
        spectrogram = tf.math.pow(spectrogram, 0.5)
        
        # ØªØ·Ø¨ÙŠØ¹
        means = tf.math.reduce_mean(spectrogram, 1, keepdims=True)
        stddevs = tf.math.reduce_std(spectrogram, 1, keepdims=True)
        spectrogram = (spectrogram - means) / (stddevs + 1e-10)
        
        return spectrogram, sample_rate.numpy()
    
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù: {e}")
        return None, None

def decode_prediction(pred):
    """ÙÙƒ ØªØ´ÙÙŠØ± ØªÙ†Ø¨Ø¤ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
    try:
        input_len = np.ones(pred.shape[0]) * pred.shape[1]
        
        # Greedy decoding
        results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]
        
        # ØªØ­ÙˆÙŠÙ„ Ù„Ù†Øµ
        output_text = []
        for result in results:
            if st.session_state.num_to_char:
                chars = st.session_state.num_to_char(result)
                text = tf.strings.reduce_join(chars).numpy().decode("utf-8")
                output_text.append(text)
        
        return output_text[0] if output_text else ""
    
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ±: {e}")
        return ""

def predict_from_audio(audio_path):
    """Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ù†Øµ Ù…Ù† Ù…Ù„Ù ØµÙˆØªÙŠ"""
    try:
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª
        spectrogram, sample_rate = process_audio_file(audio_path)
        if spectrogram is None:
            return None
        
        # Ø¥Ø¶Ø§ÙØ© Ø¨ÙØ¹Ø¯ Ø§Ù„Ø¯ÙØ¹Ø©
        spectrogram = tf.expand_dims(spectrogram, axis=0)
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤
        prediction = st.session_state.model(spectrogram, training=False)
        text = decode_prediction(prediction)
        
        return text
    
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤: {e}")
        return None

# Ø¯Ø§Ù„Ø© ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª
def record_audio(duration=5, sample_rate=16000):
    """ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª Ù…Ù† Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†"""
    try:
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ù…Ø¤Ù‚Øª
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
        temp_filename = temp_file.name
        temp_file.close()
        
        # Ø§Ù„ØªØ³Ø¬ÙŠÙ„
        recording = sd.rec(
            int(duration * sample_rate),
            samplerate=sample_rate,
            channels=1,
            dtype='int16'
        )
        
        # Ø¹Ø±Ø¶ Ø§Ù„ØªÙ‚Ø¯Ù…
        progress_placeholder = st.empty()
        progress_bar = st.progress(0)
        
        for i in range(duration):
            time.sleep(1)
            progress = (i + 1) / duration
            progress_bar.progress(progress)
            progress_placeholder.text(f"ğŸ™ï¸ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„... {i + 1}/{duration} Ø«Ø§Ù†ÙŠØ©")
        
        sd.wait()  # Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
        
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
        wavfile.write(temp_filename, sample_rate, recording)
        
        progress_placeholder.empty()
        progress_bar.empty()
        
        return temp_filename
    
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„: {e}")
        return None

# Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
if st.session_state.model is None:
    st.markdown('<div class="success-box">', unsafe_allow_html=True)
    st.info("""
    ## ğŸ¯ Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ!
    
    **Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…ØŒ ÙŠØ±Ø¬Ù‰ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ:**
    
    1. **Ø±ÙØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬**: Ù…Ù„Ù `.h5` Ø£Ùˆ `.keras`
    2. **Ø±ÙØ¹ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª**: Ù…Ù„Ù `config.json` 
    3. **Ø±ÙØ¹ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø§Øª**: Ù…Ù„Ù `preprocessors.pkl`
    
    ### ğŸ“ Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª:
    ```
    Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨/
    â”œâ”€â”€ my_model.h5           # Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­ÙÙˆØ¸
    â”œâ”€â”€ config.json           # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
    â””â”€â”€ preprocessors.pkl     # Ù…Ø¹Ø§Ù„Ø¬Ø§Øª Ø§Ù„Ù†Øµ
    ```
    """)
    st.markdown('</div>', unsafe_allow_html=True)
    
    # Ù‚Ø³Ù… Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©
    with st.expander("ğŸ†˜ Ù…Ø³Ø§Ø¹Ø¯Ø© ÙÙŠ ØªØ­Ø¶ÙŠØ± Ø§Ù„Ù…Ù„ÙØ§Øª"):
        st.markdown("""
        ### ÙƒÙŠÙÙŠØ© Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©:
        
        **1. Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (`my_model.h5`):**
        ```python
        model.save('my_model.h5')
        ```
        
        **2. Ù…Ù„Ù Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª (`config.json`):**
        ```python
        import json
        config = {
            'frame_length': 256,
            'frame_step': 160, 
            'fft_length': 384
        }
        with open('config.json', 'w') as f:
            json.dump(config, f)
        ```
        
        **3. Ù…Ù„Ù Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø§Øª (`preprocessors.pkl`):**
        ```python
        import pickle
        preprocessors = {
            'char_to_num': char_to_num,
            'num_to_char': num_to_char
        }
        with open('preprocessors.pkl', 'wb') as f:
            pickle.dump(preprocessors, f)
        ```
        """)
    
    st.stop()

# Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
st.success(f"âœ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ù…Ù„ ÙˆØ¬Ø§Ù‡Ø² Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…!")
config = st.session_state.config
st.info(f"**Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:** Frame Length: {config.get('frame_length', 'N/A')} | Frame Step: {config.get('frame_step', 'N/A')} | FFT Length: {config.get('fft_length', 'N/A')}")

# ØªØ¨ÙˆÙŠØ¨Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
tab1, tab2, tab3 = st.tabs(["ğŸ¤ ØªØ³Ø¬ÙŠÙ„ Ù…Ù† Ø§Ù„Ù…Ø§ÙŠÙƒ", "ğŸ“ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù ØµÙˆØªÙŠ", "ğŸ“Š ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡"])

with tab1:
    st.header("Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù…Ù† Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†")
    
    if not AUDIO_AVAILABLE:
        st.error("""
        âŒ **Ø®Ø§ØµÙŠØ© Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ØºÙŠØ± Ù…ØªØ§Ø­Ø©**
        
        ÙŠØ±Ø¬Ù‰ ØªØ«Ø¨ÙŠØª Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„ØµÙˆØª:
        ```bash
        pip install sounddevice scipy
        ```
        """)
    else:
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.markdown('<div class="recording-box">', unsafe_allow_html=True)
            st.subheader("ğŸ™ï¸ Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„")
            
            if st.button("âºï¸ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„", use_container_width=True, type="primary"):
                with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ø¶ÙŠØ± Ù„Ù„ØªØ³Ø¬ÙŠÙ„..."):
                    audio_file = record_audio(
                        duration=st.session_state.duration,
                        sample_rate=st.session_state.sample_rate
                    )
                    
                    if audio_file:
                        st.session_state.recorded_audio = audio_file
                        st.success("âœ… ØªÙ… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­!")
            
            if st.session_state.get('recorded_audio'):
                st.audio(st.session_state.recorded_audio, format='audio/wav')
                
                if st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ³Ø¬ÙŠÙ„", use_container_width=True):
                    with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…..."):
                        prediction = predict_from_audio(st.session_state.recorded_audio)
                        
                        if prediction:
                            st.session_state.last_prediction = prediction
                            st.rerun()
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col2:
            st.subheader("ğŸ“ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
            if st.session_state.last_prediction:
                st.markdown('<div class="result-box">', unsafe_allow_html=True)
                st.success("**Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:**")
                st.write(st.session_state.last_prediction)
                st.markdown('</div>', unsafe_allow_html=True)

with tab2:
    st.header("ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù ØµÙˆØªÙŠ")
    
    uploaded_audio = st.file_uploader("Ø§Ø®ØªØ± Ù…Ù„Ù ØµÙˆØªÙŠ WAV", type=['wav'], key="audio_upload")
    
    if uploaded_audio is not None:
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
            tmp_file.write(uploaded_audio.getvalue())
            audio_path = tmp_file.name
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù„Ù
        st.audio(uploaded_audio, format='audio/wav')
        
        if st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ", use_container_width=True):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…..."):
                prediction = predict_from_audio(audio_path)
                
                if prediction:
                    st.session_state.last_prediction = prediction
                    st.success("âœ… ØªÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­!")
                    
                    st.markdown('<div class="result-box">', unsafe_allow_html=True)
                    st.subheader("ğŸ“ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:")
                    st.write(prediction)
                    st.markdown('</div>', unsafe_allow_html=True)
                
                # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
                os.unlink(audio_path)

with tab3:
    st.header("ØªÙ‚ÙŠÙŠÙ… Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬")
    
    st.subheader("Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        reference_text = st.text_area(
            "Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ (Ø§Ù„ØµØ­ÙŠØ­):",
            placeholder="Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ø§Ù„ØµØ­ÙŠØ­ Ù‡Ù†Ø§...",
            height=100
        )
    
    with col2:
        predicted_text = st.text_area(
            "Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:",
            value=st.session_state.get('last_prediction', ''),
            placeholder="Ø³ÙŠØ¸Ù‡Ø± Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ù‡Ù†Ø§...",
            height=100
        )
    
    if st.button("ğŸ“Š Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø¯Ù‚Ø©", use_container_width=True) and reference_text and predicted_text:
        try:
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
            wer_score = wer(reference_text, predicted_text)
            cer_score = cer(reference_text, predicted_text)
            accuracy = max(0, 1 - wer_score)
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙƒÙ„Ù…Ø§Øª (WER)", f"{wer_score:.4f}")
            with col2:
                st.metric("Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­Ø±ÙˆÙ (CER)", f"{cer_score:.4f}")
            with col3:
                st.metric("Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠØ©", f"{accuracy:.2%}")
            
            # ØªÙØ³ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            if wer_score < 0.1:
                st.success("ğŸ‰ Ø¯Ù‚Ø© Ù…Ù…ØªØ§Ø²Ø©! Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ Ø±Ø§Ø¦Ø¹")
            elif wer_score < 0.3:
                st.info("âœ… Ø¯Ù‚Ø© Ø¬ÙŠØ¯Ø©! Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ Ù…Ù‚Ø¨ÙˆÙ„")
            else:
                st.warning("âš ï¸ Ø§Ù„Ø¯Ù‚Ø© ØªØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ†. Ø¬Ø±Ø¨ ØªØ³Ø¬ÙŠÙ„Ø§Øª Ø£ÙˆØ¶Ø­")
                
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­Ø³Ø§Ø¨: {e}")

# Ù‚Ø³Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
with st.expander("â„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ù†Ø¸Ø§Ù…"):
    st.markdown("""
    ### ğŸ¯ Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…:
    - âœ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ø§Ù„Ù…Ø¯Ø±Ø¨
    - âœ… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù…Ù† Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†
    - âœ… ØªØ­Ù„ÙŠÙ„ Ù…Ù„ÙØ§Øª ØµÙˆØªÙŠØ© Ù…Ø±ÙÙˆØ¹Ø©
    - âœ… ØªÙ‚ÙŠÙŠÙ… Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    - âœ… ÙˆØ§Ø¬Ù‡Ø© Ø¹Ø±Ø¨ÙŠØ© ÙƒØ§Ù…Ù„Ø©
    
    ### ğŸ’¡ Ù†ØµØ§Ø¦Ø­ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:
    1. Ø§Ø³ØªØ®Ø¯Ù… Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† Ø¬ÙŠØ¯ Ø§Ù„Ù†ÙˆØ¹ÙŠØ©
    2. ØªØ³Ø¬Ù„ ÙÙŠ Ø¨ÙŠØ¦Ø© Ù‡Ø§Ø¯Ø¦Ø©
    3. ØªØ­Ø¯Ø« Ø¨ÙˆØ¶ÙˆØ­ ÙˆØ¨Ø·Ø¡ Ù…Ø¹ØªØ¯Ù„
    4. Ø§Ø³ØªØ®Ø¯Ù… Ù…Ø¹Ø¯Ù„ Ø¹ÙŠÙ†Ø§Øª 16kHz Ù„Ù„Ø£ÙØ¶Ù„
    5. ØªØ¬Ù†Ø¨ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ Ø§Ù„Ø®Ù„ÙÙŠØ©
    """)

# ØªØ°ÙŠÙŠÙ„ Ø§Ù„ØµÙØ­Ø©
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: #666;'>"
    "ğŸ¤ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… - Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ | ØªÙ… Ø§Ù„ØªØ·ÙˆÙŠØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… TensorFlow & Streamlit"
    "</div>",
    unsafe_allow_html=True
)