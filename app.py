# -*- coding: utf-8 -*-
import streamlit as st
import tensorflow as tf
from tensorflow import keras
import numpy as np
import json
import pickle
import tempfile
import os
import time
from jiwer import wer, cer

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„ØµÙˆØª
try:
    import pyaudio
    import wave
    PYAUDIO_AVAILABLE = True
except ImportError:
    PYAUDIO_AVAILABLE = False

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
st.set_page_config(
    page_title="Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… - Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ",
    page_icon="ğŸ¤",
    layout="wide"
)

# ØªØ®ØµÙŠØµ Ø§Ù„ØªØµÙ…ÙŠÙ…
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .result-box {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        border-right: 5px solid #1f77b4;
        margin: 10px 0;
    }
    .recording-box {
        background-color: #fff3cd;
        padding: 20px;
        border-radius: 10px;
        border-left: 4px solid #ffc107;
        margin: 10px 0;
    }
    .success-box {
        background-color: #d1ecf1;
        padding: 20px;
        border-radius: 10px;
        border-left: 4px solid #0c5460;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)

# Ø§Ù„Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
st.markdown('<h1 class="main-header">ğŸ¤ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… - Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ</h1>', unsafe_allow_html=True)

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¹Ù†Ø¯ Ø§Ù„ØªØ´ØºÙŠÙ„
@st.cache_resource
def load_model_and_config():
    """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹"""
    try:
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        model = keras.models.load_model('my_model (1).h5', compile=False)
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
        with open('config.json', 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø§Øª
        with open('preprocessors.pkl', 'rb') as f:
            preprocessors = pickle.load(f)
            char_to_num = preprocessors.get('char_to_num')
            num_to_char = preprocessors.get('num_to_char')
        
        return model, config, char_to_num, num_to_char
        
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
        return None, None, None, None

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
if 'model' not in st.session_state:
    with st.spinner("ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª..."):
        model, config, char_to_num, num_to_char = load_model_and_config()
        
        if model is not None:
            st.session_state.model = model
            st.session_state.config = config
            st.session_state.char_to_num = char_to_num
            st.session_state.num_to_char = num_to_char
            st.session_state.model_loaded = True
        else:
            st.session_state.model_loaded = False

# ØªÙ‡ÙŠØ¦Ø© Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø©
if 'last_prediction' not in st.session_state:
    st.session_state.last_prediction = ""
if 'recorded_audio' not in st.session_state:
    st.session_state.recorded_audio = None

# Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØªÙŠØ©
def process_audio_file(audio_path):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù ØµÙˆØªÙŠ ÙˆØªØ­ÙˆÙŠÙ„Ù‡ Ù„Ø³Ø¨ÙŠÙƒØªØ±ÙˆØ¬Ø±Ø§Ù…"""
    try:
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
        audio = tf.io.read_file(audio_path)
        audio, sample_rate = tf.audio.decode_wav(audio)
        audio = tf.squeeze(audio, axis=-1)
        audio = tf.cast(audio, tf.float32)
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ù† config
        config = st.session_state.config
        frame_length = config.get('frame_length', 256)
        frame_step = config.get('frame_step', 160) 
        fft_length = config.get('fft_length', 384)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ø¨ÙŠÙƒØªØ±ÙˆØ¬Ø±Ø§Ù…
        spectrogram = tf.signal.stft(
            audio,
            frame_length=frame_length,
            frame_step=frame_step,
            fft_length=fft_length
        )
        spectrogram = tf.abs(spectrogram)
        spectrogram = tf.math.pow(spectrogram, 0.5)
        
        # ØªØ·Ø¨ÙŠØ¹
        means = tf.math.reduce_mean(spectrogram, 1, keepdims=True)
        stddevs = tf.math.reduce_std(spectrogram, 1, keepdims=True)
        spectrogram = (spectrogram - means) / (stddevs + 1e-10)
        
        return spectrogram, sample_rate.numpy()
    
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù: {e}")
        return None, None

def decode_prediction(pred):
    """ÙÙƒ ØªØ´ÙÙŠØ± ØªÙ†Ø¨Ø¤ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
    try:
        input_len = np.ones(pred.shape[0]) * pred.shape[1]
        
        # Greedy decoding
        results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]
        
        # ØªØ­ÙˆÙŠÙ„ Ù„Ù†Øµ
        output_text = []
        for result in results:
            if st.session_state.num_to_char:
                chars = st.session_state.num_to_char(result)
                text = tf.strings.reduce_join(chars).numpy().decode("utf-8")
                output_text.append(text)
        
        return output_text[0] if output_text else ""
    
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ±: {e}")
        return ""

def predict_from_audio(audio_path):
    """Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ù†Øµ Ù…Ù† Ù…Ù„Ù ØµÙˆØªÙŠ"""
    try:
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª
        spectrogram, sample_rate = process_audio_file(audio_path)
        if spectrogram is None:
            return None
        
        # Ø¥Ø¶Ø§ÙØ© Ø¨ÙØ¹Ø¯ Ø§Ù„Ø¯ÙØ¹Ø©
        spectrogram = tf.expand_dims(spectrogram, axis=0)
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤
        prediction = st.session_state.model(spectrogram, training=False)
        text = decode_prediction(prediction)
        
        return text
    
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤: {e}")
        return None

# Ø¯Ø§Ù„Ø© ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PyAudio
def record_audio_pyaudio(duration=5, sample_rate=16000, channels=1):
    """ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØª Ù…Ù† Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PyAudio"""
    try:
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ³Ø¬ÙŠÙ„
        chunk = 1024
        format = pyaudio.paInt16
        
        # Ø¥Ù†Ø´Ø§Ø¡ ÙƒØ§Ø¦Ù† PyAudio
        p = pyaudio.PyAudio()
        
        # ÙØªØ­ stream Ù„Ù„ØªØ³Ø¬ÙŠÙ„
        stream = p.open(
            format=format,
            channels=channels,
            rate=sample_rate,
            input=True,
            frames_per_buffer=chunk
        )
        
        st.info("ğŸ™ï¸ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„... ØªÙƒÙ„Ù… Ø§Ù„Ø¢Ù†!")
        
        frames = []
        
        # Ø­Ø³Ø§Ø¨ Ø¹Ø¯Ø¯ Ø§Ù„Ù‚Ø·Ø¹ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
        total_chunks = int((sample_rate / chunk) * duration)
        
        # Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù…
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # Ø§Ù„ØªØ³Ø¬ÙŠÙ„
        for i in range(total_chunks):
            data = stream.read(chunk)
            frames.append(data)
            
            # ØªØ­Ø¯ÙŠØ« Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù…
            progress = (i + 1) / total_chunks
            progress_bar.progress(progress)
            status_text.text(f"â³ {int(progress * 100)}% - {i + 1}/{total_chunks}")
        
        # Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ³Ø¬ÙŠÙ„
        stream.stop_stream()
        stream.close()
        p.terminate()
        
        progress_bar.empty()
        status_text.empty()
        
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
        temp_filename = temp_file.name
        temp_file.close()
        
        # Ø­ÙØ¸ ÙƒÙ…Ù„Ù WAV
        wf = wave.open(temp_filename, 'wb')
        wf.setnchannels(channels)
        wf.setsampwidth(p.get_sample_size(format))
        wf.setframerate(sample_rate)
        wf.writeframes(b''.join(frames))
        wf.close()
        
        st.success("âœ… ØªÙ… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­!")
        return temp_filename
        
    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„: {e}")
        return None

# Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
if not st.session_state.get('model_loaded', False):
    st.error("""
    âŒ **Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­**
    
    **ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ù„ÙØ§Øª ÙÙŠ Ù†ÙØ³ Ø§Ù„Ù…Ø¬Ù„Ø¯:**
    - `my_model (1).h5` - Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨
    - `config.json` - Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©  
    - `preprocessors.pkl` - Ù…Ø¹Ø§Ù„Ø¬Ø§Øª Ø§Ù„Ù†Øµ
    
    **Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø­Ù„:**
    1. ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ù†ÙØ³ Ù…Ø¬Ù„Ø¯ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
    2. ØªØ£ÙƒØ¯ Ø£Ù† Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…Ù„ÙØ§Øª Ù…Ø·Ø§Ø¨Ù‚Ø© ØªÙ…Ø§Ù…Ø§Ù‹
    3. Ø¬Ø¯Ø¯ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø©
    """)
    st.stop()

# Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
st.success("âœ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ù…Ù„ ÙˆØ¬Ø§Ù‡Ø² Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…!")
config = st.session_state.config
st.info(f"**Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:** Frame Length: {config.get('frame_length')} | Frame Step: {config.get('frame_step')} | FFT Length: {config.get('fft_length')}")

# Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ù„Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
with st.sidebar:
    st.header("âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ³Ø¬ÙŠÙ„")
    
    if PYAUDIO_AVAILABLE:
        duration = st.slider("Ù…Ø¯Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„ (Ø«ÙˆØ§Ù†ÙŠ)", 1, 15, 5)
        sample_rate = st.selectbox("Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª", [16000, 22050, 44100], index=0)
        channels = st.selectbox("Ø¹Ø¯Ø¯ Ø§Ù„Ù‚Ù†ÙˆØ§Øª", [1, 2], index=0)
    else:
        st.error("""
        âŒ **PyAudio ØºÙŠØ± Ù…Ø«Ø¨Øª**
        
        Ù„Ù„ØªØ³Ø¬ÙŠÙ„ Ù…Ù† Ø§Ù„Ù…Ø§ÙŠÙƒØ±ÙˆÙÙˆÙ†:
        ```bash
        pip install pyaudio
        ```
        """)

# ØªØ¨ÙˆÙŠØ¨Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
tab1, tab2, tab3 = st.tabs(["ğŸ¤ ØªØ³Ø¬ÙŠÙ„ Ù…Ù† Ø§Ù„Ù…Ø§ÙŠÙƒ", "ğŸ“ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù ØµÙˆØªÙŠ", "ğŸ“Š ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡"])

with tab1:
    st.header("Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù…Ù† Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†")
    
    if not PYAUDIO_AVAILABLE:
        st.error("""
        ## âŒ Ø®Ø§ØµÙŠØ© Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ØºÙŠØ± Ù…ØªØ§Ø­Ø©
        
        **Ù„ØªÙ…ÙƒÙŠÙ† Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ù…Ù† Ø§Ù„Ù…Ø§ÙŠÙƒØ±ÙˆÙÙˆÙ†:**
        
        **Ø¹Ù„Ù‰ Windows:**
        ```bash
        pip install pipwin
        pipwin install pyaudio
        ```
        
        **Ø¹Ù„Ù‰ Mac/Linux:**
        ```bash
        pip install pyaudio
        ```
        
        **Ø¨Ø¯ÙŠÙ„ ÙÙˆØ±ÙŠ:** Ø§Ø³ØªØ®Ø¯Ù… ØªØ¨ÙˆÙŠØ¨ "ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù ØµÙˆØªÙŠ" Ù„Ø±ÙØ¹ ØªØ³Ø¬ÙŠÙ„Ø§Øª Ø¬Ø§Ù‡Ø²Ø©
        """)
    else:
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.markdown('<div class="recording-box">', unsafe_allow_html=True)
            st.subheader("ğŸ™ï¸ Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„ØªØ³Ø¬ÙŠÙ„")
            
            if st.button("âºï¸ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„", use_container_width=True, type="primary"):
                with st.spinner("Ø¬Ø§Ø±ÙŠ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„..."):
                    audio_file = record_audio_pyaudio(
                        duration=duration,
                        sample_rate=sample_rate,
                        channels=channels
                    )
                    
                    if audio_file:
                        st.session_state.recorded_audio = audio_file
                        st.rerun()
            
            # Ø¹Ø±Ø¶ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø¥Ø°Ø§ Ù…ÙˆØ¬ÙˆØ¯
            if st.session_state.recorded_audio:
                st.audio(st.session_state.recorded_audio, format='audio/wav')
                
                col_btn1, col_btn2 = st.columns(2)
                
                with col_btn1:
                    if st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ³Ø¬ÙŠÙ„", use_container_width=True):
                        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…..."):
                            prediction = predict_from_audio(st.session_state.recorded_audio)
                            
                            if prediction:
                                st.session_state.last_prediction = prediction
                                st.success("âœ… ØªÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­!")
                                st.rerun()
                
                with col_btn2:
                    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„ØªØ³Ø¬ÙŠÙ„", use_container_width=True):
                        try:
                            if st.session_state.recorded_audio and os.path.exists(st.session_state.recorded_audio):
                                os.unlink(st.session_state.recorded_audio)
                            st.session_state.recorded_audio = None
                            st.session_state.last_prediction = ""
                            st.rerun()
                        except:
                            pass
            
            st.markdown('</div>', unsafe_allow_html=True)
        
        with col2:
            st.subheader("ğŸ“ Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
            if st.session_state.last_prediction:
                st.markdown('<div class="result-box">', unsafe_allow_html=True)
                st.success("**Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:**")
                st.write(st.session_state.last_prediction)
                
                # Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø§Ù„Ù†Øµ
                text_length = len(st.session_state.last_prediction)
                word_count = len(st.session_state.last_prediction.split())
                
                col_stat1, col_stat2 = st.columns(2)
                with col_stat1:
                    st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ø±ÙˆÙ", text_length)
                with col_stat2:
                    st.metric("Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª", word_count)
                
                st.markdown('</div>', unsafe_allow_html=True)
            else:
                st.info("ğŸ‘† Ø³Ø¬Ù„ ØµÙˆØªØ§Ù‹ Ø£ÙˆÙ„Ø§Ù‹ Ø«Ù… Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ³Ø¬ÙŠÙ„")

with tab2:
    st.header("ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù ØµÙˆØªÙŠ")
    
    uploaded_audio = st.file_uploader("Ø§Ø®ØªØ± Ù…Ù„Ù ØµÙˆØªÙŠ WAV", type=['wav'], key="audio_upload")
    
    if uploaded_audio is not None:
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
            tmp_file.write(uploaded_audio.getvalue())
            audio_path = tmp_file.name
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù„Ù
            st.audio(uploaded_audio, format='audio/wav')
        
        with col2:
            # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù„Ù
            file_size = len(uploaded_audio.getvalue()) / 1024
            st.metric("Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù", f"{file_size:.1f} KB")
            st.metric("Ø§Ù„Ù†ÙˆØ¹", "WAV")
        
        if st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ", use_container_width=True):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…..."):
                prediction = predict_from_audio(audio_path)
                
                if prediction:
                    st.session_state.last_prediction = prediction
                    st.success("âœ… ØªÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­!")
                    
                    st.markdown('<div class="result-box">', unsafe_allow_html=True)
                    st.subheader("ğŸ“ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:")
                    st.write(prediction)
                    
                    # Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø§Ù„Ù†Øµ
                    text_length = len(prediction)
                    word_count = len(prediction.split())
                    
                    col_stat1, col_stat2 = st.columns(2)
                    with col_stat1:
                        st.metric("Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ø±ÙˆÙ", text_length)
                    with col_stat2:
                        st.metric("Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª", word_count)
                    
                    st.markdown('</div>', unsafe_allow_html=True)
                
                # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª
                try:
                    os.unlink(audio_path)
                except:
                    pass

with tab3:
    st.header("ØªÙ‚ÙŠÙŠÙ… Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬")
    
    st.subheader("Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        reference_text = st.text_area(
            "Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ (Ø§Ù„ØµØ­ÙŠØ­):",
            placeholder="Ø£Ø¯Ø®Ù„ Ø§Ù„Ù†Øµ Ø§Ù„ØµØ­ÙŠØ­ Ù‡Ù†Ø§...",
            height=120,
            key="ref_text"
        )
    
    with col2:
        predicted_text = st.text_area(
            "Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:",
            value=st.session_state.get('last_prediction', ''),
            placeholder="Ø³ÙŠØ¸Ù‡Ø± Ø§Ù„Ù†Øµ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹ Ù‡Ù†Ø§...",
            height=120,
            key="pred_text"
        )
    
    if st.button("ğŸ“Š Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø¯Ù‚Ø©", use_container_width=True) and reference_text and predicted_text:
        try:
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
            wer_score = wer(reference_text, predicted_text)
            cer_score = cer(reference_text, predicted_text)
            accuracy = max(0, 1 - wer_score)
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙƒÙ„Ù…Ø§Øª (WER)", f"{wer_score:.4f}")
            with col2:
                st.metric("Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­Ø±ÙˆÙ (CER)", f"{cer_score:.4f}")
            with col3:
                st.metric("Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠØ©", f"{accuracy:.2%}")
            
            # ØªÙØ³ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            st.subheader("ğŸ“ˆ ØªÙØ³ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
            if wer_score == 0:
                st.success("ğŸ‰ **Ù…Ù…ØªØ§Ø²**: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ Ø¨Ø´ÙƒÙ„ ÙƒØ§Ù…Ù„!")
            elif wer_score < 0.1:
                st.success("ğŸ”¹ **Ù…Ù…ØªØ§Ø²**: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¹Ù…Ù„ Ø¨Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹")
            elif wer_score < 0.3:
                st.info("ğŸ”¸ **Ø¬ÙŠØ¯**: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¹Ù…Ù„ Ø¨Ø¯Ù‚Ø© Ù…Ù‚Ø¨ÙˆÙ„Ø©")
            elif wer_score < 0.5:
                st.warning("âš ï¸ **Ù…ØªÙˆØ³Ø·**: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ­ØªØ§Ø¬ Ù„ØªØ­Ø³ÙŠÙ†")
            else:
                st.error("âŒ **Ù…Ù†Ø®ÙØ¶**: Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù†Ø®ÙØ¶Ø© ÙˆØªØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ† ÙƒØ¨ÙŠØ±")
                
        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³: {e}")

# Ù‚Ø³Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
with st.expander("â„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ù†Ø¸Ø§Ù…"):
    st.markdown("""
    ### ğŸ¯ Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…:
    - âœ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª
    - âœ… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù…Ù† Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† (PyAudio)
    - âœ… ØªØ­Ù„ÙŠÙ„ Ù…Ù„ÙØ§Øª ØµÙˆØªÙŠØ© Ù…Ø±ÙÙˆØ¹Ø©  
    - âœ… ØªÙ‚ÙŠÙŠÙ… Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    - âœ… ÙˆØ§Ø¬Ù‡Ø© Ø¹Ø±Ø¨ÙŠØ© ÙƒØ§Ù…Ù„Ø©
    - âœ… Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø§Ù„Ù†Øµ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
    
    ### ğŸ’¡ Ù†ØµØ§Ø¦Ø­ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:
    1. **Ø§Ø³ØªØ®Ø¯Ù… Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† Ø¬ÙŠØ¯** Ø§Ù„Ù†ÙˆØ¹ÙŠØ©
    2. **Ø³Ø¬Ù„ ÙÙŠ Ø¨ÙŠØ¦Ø© Ù‡Ø§Ø¯Ø¦Ø©** Ø¨Ø¹ÙŠØ¯Ø§Ù‹ Ø¹Ù† Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
    3. **ØªØ­Ø¯Ø« Ø¨ÙˆØ¶ÙˆØ­** ÙˆØ¨Ø·Ø¡ Ù…Ø¹ØªØ¯Ù„
    4. **Ø§Ø³ØªØ®Ø¯Ù… Ù…Ø¹Ø¯Ù„ Ø¹ÙŠÙ†Ø§Øª 16kHz** Ù„Ù„Ø£ÙØ¶Ù„
    5. **ØªØ¬Ù†Ø¨ Ø§Ù„ØµØ¯Ù‰** ÙˆØ§Ù„Ø¶ÙˆØ¶Ø§Ø¡ Ø§Ù„Ø®Ù„ÙÙŠØ©
    """)

# ØªØ°ÙŠÙŠÙ„ Ø§Ù„ØµÙØ­Ø©
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: #666;'>"
    "ğŸ¤ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… - Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ù…Ù„ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ ğŸš€"
    "</div>",
    unsafe_allow_html=True
)